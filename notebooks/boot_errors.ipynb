{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "from src.boot import boot_sample, compute_treatment_effects, aggregate_treatment_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ATT(B, g, delta, your_data, unit_id, time):\n",
    "    \"\"\"\n",
    "    B: Number of bootstrap samples\n",
    "    g: Parameter g\n",
    "    delta: Parameter delta\n",
    "    your_data: The data you are working with, format depends on your needs\n",
    "    unit_id: Column name for unit IDs\n",
    "    time: Column name for time\n",
    "    \"\"\"\n",
    "    ATT_bootstrap_results = []\n",
    "    R_bootstrap_results = []\n",
    "    param_cov_matrices = []  # To store covariance matrices from each bootstrap\n",
    "    \n",
    "    for b in range(B):\n",
    "        # Step 1: Use boot_sample to draw the bootstrap sample\n",
    "        bs_data = boot_sample(your_data, unit_id, time)\n",
    "        \n",
    "        # Step 2: Modularized computation of ATT_hat_star and its covariance matrix\n",
    "        ATT_hat_star, cov_matrix = compute_ATT(bs_data)  # Make compute_ATT return covariance matrix\n",
    "        param_cov_matrices.append(cov_matrix)\n",
    "        \n",
    "        # Forming R_hat_star\n",
    "        R_hat_star = np.sqrt(n) * (ATT_hat_star - ATT_hat)\n",
    "        \n",
    "        # Storing results\n",
    "        ATT_bootstrap_results.append(ATT_hat_star)\n",
    "        R_bootstrap_results.append(R_hat_star)\n",
    "        \n",
    "    # Step 4: Bootstrap estimator of Sigma^(1/2)\n",
    "    q_75 = np.percentile(R_bootstrap_results, 75)\n",
    "    q_25 = np.percentile(R_bootstrap_results, 25)\n",
    "    z_75 = stats.norm.ppf(0.75)\n",
    "    z_25 = stats.norm.ppf(0.25)\n",
    "    sigma_half_hat = (q_75 - q_25) / (z_75 - z_25)\n",
    "    \n",
    "    # Step 5 and 6: Compute t-tests and empirical quantiles\n",
    "    t_tests = [np.abs(R) / sigma_half_hat for R in R_bootstrap_results]\n",
    "    c_1_alpha = np.percentile(t_tests, 95)  # Assuming alpha = 0.05\n",
    "    \n",
    "    # Step 7: Construct confidence bands (Extendable to simultaneous intervals)\n",
    "    ATT_hat_nev_dr, _ = compute_ATT(None, your_data)  \n",
    "    confidence_band = [ATT_hat_nev_dr + c_1_alpha * sigma_half_hat / np.sqrt(n),\n",
    "                       ATT_hat_nev_dr - c_1_alpha * sigma_half_hat / np.sqrt(n)]\n",
    "    \n",
    "    # Average parameter covariance matrix over all bootstraps\n",
    "    avg_param_cov_matrix = np.mean(param_cov_matrices, axis=0)\n",
    "    \n",
    "    # Standard errors from the diagonal of the average covariance matrix\n",
    "    param_std_errors = np.sqrt(np.diag(avg_param_cov_matrix))\n",
    "    \n",
    "    return confidence_band, param_std_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of units, time periods, and cohorts\n",
    "n_units = 10\n",
    "n_time = 10\n",
    "n_cohorts = 3\n",
    "\n",
    "# Random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'unit_id': np.repeat(range(1, n_units + 1), n_time),\n",
    "    'time_id': list(range(1, n_time + 1)) * n_units,\n",
    "    'treatment': np.random.choice([0, 1], n_units * n_time),\n",
    "    'covariate1': np.random.normal(0, 1, n_units * n_time),\n",
    "    'covariate2': np.random.normal(0, 1, n_units * n_time),\n",
    "    'cohort': np.random.choice([2010, 2011, 2012], n_units * n_time)\n",
    "})\n",
    "\n",
    "# Adding a few never-treated units\n",
    "df.loc[df['unit_id'].isin([1, 2]), 'treatment'] = 0\n",
    "\n",
    "# Simulating potential outcomes under the control (Y0)\n",
    "df['Y0'] = 5 + 0.5 * df['covariate1'] + 0.3 * df['covariate2'] + 0.2 * df['unit_id'] + 0.1 * df['time_id'] + np.random.normal(0, 1, n_units * n_time)\n",
    "\n",
    "# Defining treatment effect (constant for all units as 2)\n",
    "df['treatment_effect'] = 2\n",
    "\n",
    "# Simulating potential outcomes under the treatment (Y1)\n",
    "df['Y1'] = df['Y0'] + df['treatment_effect']\n",
    "\n",
    "# Constructing the observed outcome based on treatment status\n",
    "df['outcome'] = np.where(df['treatment'] == 1, df['Y1'], df['Y0'])\n",
    "\n",
    "# Adding pre-treatment and post-treatment periods (assuming treatment starts at time 5 for everyone)\n",
    "df['period_type'] = np.where(df['time_id'] < 5, 'pre-treatment', 'post-treatment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = compute_treatment_effects(df, 'outcome', 'treatment', 'unit_id', 'time_id', covariates=['covariate1', 'covariate2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = result_df.copy()\n",
    "data = data[data['treatment'] == 1]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the aggregate effects function\n",
    "print(aggregate_treatment_effects(data, 't_effects', estimand='overall'))\n",
    "print(aggregate_treatment_effects(data, 't_effects', estimand='cohort', groupby_column='cohort', time_column='time_id'))\n",
    "print(aggregate_treatment_effects(data, 't_effects', estimand='event', groupby_column='cohort' ,time_column='time_id'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
