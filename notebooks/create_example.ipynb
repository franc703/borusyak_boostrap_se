{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate your model\n",
    "def run_model(data):\n",
    "    X = sm.add_constant(data[['x1', 'x2']])\n",
    "    y = data['y']\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    return model.params['x1'], model.bse['x1']\n",
    "\n",
    "# Bootstrap-t function\n",
    "def bootstrap_t(df, model_func, B=1000, alpha=0.05):\n",
    "    N = len(df['entity'].unique())\n",
    "    original_estimate, _ = model_func(df)\n",
    "\n",
    "    bootstrap_estimates = np.zeros(B)\n",
    "    for b in range(B):\n",
    "        bootstrap_sample = df.sample(frac=1, replace=True)\n",
    "        bootstrap_estimate, _ = model_func(bootstrap_sample)\n",
    "        bootstrap_estimates[b] = np.sqrt(N) * (bootstrap_estimate - original_estimate)\n",
    "\n",
    "    q25, q75 = np.percentile(bootstrap_estimates, [25, 75])\n",
    "    z25, z75 = stats.norm.ppf([0.25, 0.75])\n",
    "    normalization_factor = (q75 - q25) / (z75 - z25)\n",
    "\n",
    "    normalized_t_stats = bootstrap_estimates / normalization_factor\n",
    "    lower_percentile = np.percentile(normalized_t_stats, 100 * (alpha / 2))\n",
    "    upper_percentile = np.percentile(normalized_t_stats, 100 * (1 - alpha / 2))\n",
    "\n",
    "    SE_original_estimate = np.std(bootstrap_estimates)\n",
    "    CI_lower = original_estimate - upper_percentile * SE_original_estimate\n",
    "    CI_upper = original_estimate - lower_percentile * SE_original_estimate\n",
    "\n",
    "    return original_estimate, CI_lower, CI_upper, SE_original_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Results:\n",
      "Original Estimate: -0.03942280690283285\n",
      "Bootstrap Confidence Interval: (-0.590087548044941, 0.5499552657649268)\n",
      "Bootstrap Standard Error: 0.30706585835553074\n",
      "\n",
      "Statsmodels Results:\n",
      "Estimate: -0.03942280690283285\n",
      "Confidence Interval: (-0.1003013460770375, 0.021455732271371805)\n",
      "Standard Error: 0.031060479170512578\n"
     ]
    }
   ],
   "source": [
    "# Simulated data\n",
    "N = 100\n",
    "T = 10\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({\n",
    "    'y': np.random.randn(N * T),\n",
    "    'x1': np.random.randn(N * T),\n",
    "    'x2': np.random.randn(N * T),\n",
    "    'entity': np.array([[i] * T for i in range(N)]).flatten(),\n",
    "    'time': np.array([list(range(T)) for _ in range(N)]).flatten()\n",
    "})\n",
    "\n",
    "# Bootstrap results\n",
    "original_estimate, CI_lower, CI_upper, bootstrap_SE = bootstrap_t(df, run_model)\n",
    "print(f\"Bootstrap Results:\")\n",
    "print(f\"Original Estimate: {original_estimate}\")\n",
    "print(f\"Bootstrap Confidence Interval: ({CI_lower}, {CI_upper})\")\n",
    "print(f\"Bootstrap Standard Error: {bootstrap_SE}\")\n",
    "\n",
    "# Statsmodels results\n",
    "X = sm.add_constant(df[['x1', 'x2']])\n",
    "y = df['y']\n",
    "model = sm.OLS(y, X).fit()\n",
    "statsmodels_estimate = model.params['x1']\n",
    "statsmodels_SE = model.bse['x1']\n",
    "statsmodels_CI_lower = statsmodels_estimate - 1.96 * statsmodels_SE\n",
    "statsmodels_CI_upper = statsmodels_estimate + 1.96 * statsmodels_SE\n",
    "\n",
    "print(f\"\\nStatsmodels Results:\")\n",
    "print(f\"Estimate: {statsmodels_estimate}\")\n",
    "print(f\"Confidence Interval: ({statsmodels_CI_lower}, {statsmodels_CI_upper})\")\n",
    "print(f\"Standard Error: {statsmodels_SE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... (previous code remains unchanged)\n",
    "\n",
    "# Block Bootstrap-t function\n",
    "def block_bootstrap_t(df, model_func, B=1000, alpha=0.05):\n",
    "    N = len(df['entity'].unique())\n",
    "    \n",
    "    original_estimate, original_se = model_func(df)\n",
    "    block_ids = df['entity'].unique()\n",
    "\n",
    "    bootstrap_estimates = np.zeros(B)\n",
    "    bootstrap_se = np.zeros(B)\n",
    "\n",
    "    for b in range(B):\n",
    "        sampled_blocks = np.random.choice(block_ids, size=N, replace=True)\n",
    "        bootstrap_sample = df[df['entity'].isin(sampled_blocks)]\n",
    "        \n",
    "        bootstrap_estimate, bootstrap_std_error = model_func(bootstrap_sample)\n",
    "        bootstrap_estimates[b] = bootstrap_estimate\n",
    "        bootstrap_se[b] = bootstrap_std_error\n",
    "\n",
    "    # Studentized bootstrap\n",
    "    t_star = (bootstrap_estimates - original_estimate) / bootstrap_se\n",
    "    bootstrap_se_estimate = np.std(t_star)  # Bootstrap standard error\n",
    "    lower = np.percentile(t_star, 100 * alpha / 2)\n",
    "    upper = np.percentile(t_star, 100 * (1 - alpha / 2))\n",
    "    \n",
    "    CI_lower = original_estimate - upper * original_se\n",
    "    CI_upper = original_estimate - lower * original_se\n",
    "    \n",
    "    return original_estimate, CI_lower, CI_upper, bootstrap_se_estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block Bootstrap Results:\n",
      "Original Estimate: -0.03942280690283285\n",
      "Block Bootstrap Confidence Interval: (-0.07340271790063685, -0.0030960253386790246)\n",
      "Bootstrap Standard Error: 0.5597827362359974\n",
      "\n",
      "Statsmodels Results:\n",
      "Estimate: -0.03942280690283285\n",
      "Confidence Interval: (-0.1003013460770375, 0.021455732271371805)\n",
      "Standard Error: 0.031060479170512578\n"
     ]
    }
   ],
   "source": [
    "# Simulated data\n",
    "N = 100\n",
    "T = 10\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({\n",
    "    'y': np.random.randn(N * T),\n",
    "    'x1': np.random.randn(N * T),\n",
    "    'x2': np.random.randn(N * T),\n",
    "    'entity': np.array([[i] * T for i in range(N)]).flatten(),\n",
    "    'time': np.array([list(range(T)) for _ in range(N)]).flatten()\n",
    "})\n",
    "\n",
    "# Block Bootstrap results\n",
    "original_estimate, CI_lower, CI_upper, bootstrap_se_estimate = block_bootstrap_t(df, run_model)\n",
    "print(f\"Block Bootstrap Results:\")\n",
    "print(f\"Original Estimate: {original_estimate}\")\n",
    "print(f\"Block Bootstrap Confidence Interval: ({CI_lower}, {CI_upper})\")\n",
    "print(f\"Bootstrap Standard Error: {bootstrap_se_estimate}\")\n",
    "\n",
    "# Statsmodels results\n",
    "X = sm.add_constant(df[['x1', 'x2']])\n",
    "y = df['y']\n",
    "model = sm.OLS(y, X).fit()\n",
    "statsmodels_estimate = model.params['x1']\n",
    "statsmodels_SE = model.bse['x1']\n",
    "statsmodels_CI_lower = statsmodels_estimate - 1.96 * statsmodels_SE\n",
    "statsmodels_CI_upper = statsmodels_estimate + 1.96 * statsmodels_SE\n",
    "\n",
    "print(f\"\\nStatsmodels Results:\")\n",
    "print(f\"Estimate: {statsmodels_estimate}\")\n",
    "print(f\"Confidence Interval: ({statsmodels_CI_lower}, {statsmodels_CI_upper})\")\n",
    "print(f\"Standard Error: {statsmodels_SE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap-t Results:\n",
      "Original Estimate: -0.03966116022360016\n",
      "Bootstrap-t Confidence Interval: (-0.1010221301937804, 0.02226658865685311)\n",
      "Bootstrap-t Standard Error: 0.31372040631252984\n",
      "\n",
      "Statsmodels Results:\n",
      "Estimate: -0.03966116022360016\n",
      "Confidence Interval: (-0.10059247702789614, 0.02127015658069583)\n",
      "Standard Error: 0.03105027537440998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Dummy function to simulate your model (Replace with your actual model)\n",
    "def run_model(df):\n",
    "    X = sm.add_constant(df['x'])\n",
    "    model = sm.OLS(df['y'], X).fit()\n",
    "    return model.params['x'], model.bse['x']\n",
    "\n",
    "# Simplified Bootstrap-t function\n",
    "def bootstrap_t(df, model_func, B=1000, alpha=0.05):\n",
    "    N = len(df['entity'].unique())\n",
    "    original_estimate, _ = model_func(df)\n",
    "\n",
    "    bootstrap_estimates = np.zeros(B)\n",
    "    for b in range(B):\n",
    "        bootstrap_sample = df.sample(frac=1, replace=True)\n",
    "        bootstrap_estimate, _ = model_func(bootstrap_sample)\n",
    "        bootstrap_estimates[b] = np.sqrt(N) * (bootstrap_estimate - original_estimate)\n",
    "\n",
    "    lower_percentile = np.percentile(bootstrap_estimates, 100 * (alpha / 2))\n",
    "    upper_percentile = np.percentile(bootstrap_estimates, 100 * (1 - alpha / 2))\n",
    "\n",
    "    SE_original_estimate = np.std(bootstrap_estimates)\n",
    "\n",
    "    CI_lower = original_estimate - upper_percentile / np.sqrt(N)\n",
    "    CI_upper = original_estimate - lower_percentile / np.sqrt(N)\n",
    "\n",
    "    return original_estimate, CI_lower, CI_upper, SE_original_estimate\n",
    "\n",
    "# Simulated data: Replace with your actual panel data\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({\n",
    "    'y': np.random.normal(0, 1, 1000),\n",
    "    'x': np.random.normal(0, 1, 1000),\n",
    "    'entity': np.array([i//10 for i in range(1000)])\n",
    "})\n",
    "\n",
    "# Run Bootstrap-t\n",
    "original_estimate, CI_lower, CI_upper, SE_bootstrap = bootstrap_t(df, run_model, B=10000)\n",
    "print(f\"Bootstrap-t Results:\")\n",
    "print(f\"Original Estimate: {original_estimate}\")\n",
    "print(f\"Bootstrap-t Confidence Interval: ({CI_lower}, {CI_upper})\")\n",
    "print(f\"Bootstrap-t Standard Error: {SE_bootstrap}\")\n",
    "\n",
    "# Run Statsmodels\n",
    "X = sm.add_constant(df['x'])\n",
    "model = sm.OLS(df['y'], X).fit()\n",
    "statsmodels_estimate = model.params['x']\n",
    "statsmodels_se = model.bse['x']\n",
    "statsmodels_CI = model.conf_int(alpha=0.05).loc['x']\n",
    "\n",
    "print(f\"\\nStatsmodels Results:\")\n",
    "print(f\"Estimate: {statsmodels_estimate}\")\n",
    "print(f\"Confidence Interval: ({statsmodels_CI[0]}, {statsmodels_CI[1]})\")\n",
    "print(f\"Standard Error: {statsmodels_se}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      entity    period          y   cohort  treatment\n",
      "0  cohort1_1  period_1  69.185913  cohort1          0\n",
      "1  cohort1_2  period_1  36.904025  cohort1          0\n",
      "2  cohort1_3  period_1  52.336826  cohort1          0\n",
      "3  cohort1_4  period_1  56.729106  cohort1          0\n",
      "4  cohort1_5  period_1  24.440386  cohort1          0\n"
     ]
    }
   ],
   "source": [
    "# Setting a seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Number of entities in each cohort and periods\n",
    "n_entities_cohort1 = 50\n",
    "n_entities_cohort2 = 50\n",
    "n_entities_cohort3 = 50\n",
    "n_periods = 5\n",
    "\n",
    "# Generate a base level for outcome variable Y for each cohort and period (let's say income)\n",
    "base_y_cohort1 = np.random.normal(50, 10, (n_entities_cohort1, n_periods))\n",
    "base_y_cohort2 = np.random.normal(60, 10, (n_entities_cohort2, n_periods))\n",
    "base_y_cohort3 = np.random.normal(55, 10, (n_entities_cohort3, n_periods))\n",
    "\n",
    "# Treatment effects (these will vary by cohort and period)\n",
    "# Assume these are the true treatment effects you want to estimate\n",
    "treatment_effects_cohort1 = np.array([0, 0, 5, 5, 5])  # Treated in period 3\n",
    "treatment_effects_cohort2 = np.array([0, 0, 0, 7, 7])  # Treated in period 4\n",
    "treatment_effects_cohort3 = np.array([0, 0, 0, 0, 0])  # Never treated\n",
    "\n",
    "# Apply treatment effects to the Y variable (plus some random noise for each individual)\n",
    "for i in range(n_periods):\n",
    "    base_y_cohort1[:, i] += treatment_effects_cohort1[i] + np.random.normal(0, 2, n_entities_cohort1)  # Assume a std error of 2\n",
    "    base_y_cohort2[:, i] += treatment_effects_cohort2[i] + np.random.normal(0, 2, n_entities_cohort2)  # Assume a std error of 2\n",
    "    base_y_cohort3[:, i] += treatment_effects_cohort3[i] + np.random.normal(0, 2, n_entities_cohort3)  # Assume a std error of 2\n",
    "\n",
    "# Prepare data frame\n",
    "df_cohort1 = pd.DataFrame(base_y_cohort1, columns=[f'period_{i+1}' for i in range(n_periods)])\n",
    "df_cohort1['entity'] = [f'cohort1_{i+1}' for i in range(n_entities_cohort1)]\n",
    "df_cohort1 = df_cohort1.melt(id_vars=['entity'], var_name='period', value_name='y')\n",
    "\n",
    "df_cohort2 = pd.DataFrame(base_y_cohort2, columns=[f'period_{i+1}' for i in range(n_periods)])\n",
    "df_cohort2['entity'] = [f'cohort2_{i+1}' for i in range(n_entities_cohort2)]\n",
    "df_cohort2 = df_cohort2.melt(id_vars=['entity'], var_name='period', value_name='y')\n",
    "\n",
    "df_cohort3 = pd.DataFrame(base_y_cohort3, columns=[f'period_{i+1}' for i in range(n_periods)])\n",
    "df_cohort3['entity'] = [f'cohort3_{i+1}' for i in range(n_entities_cohort3)]\n",
    "df_cohort3 = df_cohort3.melt(id_vars=['entity'], var_name='period', value_name='y')\n",
    "\n",
    "# Combine all cohorts into one DataFrame\n",
    "df = pd.concat([df_cohort1, df_cohort2, df_cohort3], ignore_index=True)\n",
    "\n",
    "# Add a cohort indicator\n",
    "df['cohort'] = df['entity'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "# Add a treatment indicator (1 if treated, 0 otherwise)\n",
    "df['treatment'] = 0\n",
    "df.loc[(df['cohort'] == 'cohort1') & (df['period'].isin(['period_3', 'period_4', 'period_5'])), 'treatment'] = 1\n",
    "df.loc[(df['cohort'] == 'cohort2') & (df['period'].isin(['period_4', 'period_5'])), 'treatment'] = 1\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
